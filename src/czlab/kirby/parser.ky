;; Copyright (c) 2013-2017, Kenneth Leung. All rights reserved.
;; The use and distribution terms for this software are covered by the
;; Eclipse Public License 1.0 (http://opensource.org/licenses/eclipse-1.0.php)
;; which can be found in the file epl-v10.html at the root of this distribution.
;; By using this software in any fashion, you are agreeing to be bound by
;; the terms of this license.
;; You must not remove this notice, or any other, from this software.
(ns ^{:doc ""
      :author "Kenneth Leung"}
  czlab.kirby.parser
  (require ["source-map" :as smap])
  (require ["./stdlib"
            :as std
            :refer [lambda-arg object? nichts? count
                    into! vector conj! prn
                    slice opt?? symbol
                    keyword contains? list not-empty]]))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn tnodeEx "Create a token"
  [chunk name] (tnode nil nil nil chunk name))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn tnode "Create a token
            with source information"
  [&[source line col chunk name]]
  (new smap/SourceNode
       line col source chunk (opt?? name "")))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(const REGEX {
  id /^[a-zA-Z_$][\/.?\-*!0-9a-zA-Z_'<>%#@$\+]*$/
  id2 /^[*\-][\/.?\-*!0-9a-zA-Z_'<>%#@$\+]+$/
  float /^[-+]?[0-9]+\.[0-9]+$/
  int /^[-+]?[0-9]+$/
  hex /^[-+]?0x/
  dquoteHat /^"/
  dquoteEnd /"$/
  func /^function\b/
  slash /\//g
  query /\?/g
  perc /%/g
  bang /!/g
  plus /\+/g
  dash /-/g
  quote /'/g
  hash /#/g
  at /@/g
  less /</g
  greater />/g
  star /\*/g
  wspace /\s/})

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(const- REPLACERS
  [[REGEX.query "_QUERY_"] [REGEX.bang "_BANG_"] [REGEX.dash "_DASH_"]
   [REGEX.quote "_QUOTE_"] [REGEX.hash "_HASH_"] [REGEX.plus "_PLUS_"]
   [REGEX.perc "_PERC_"] [REGEX.at "_AT_"] [REGEX.less "_LT_"]
   [REGEX.greater "_GT_"] [REGEX.star "_STAR_"]])

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn testid? "Returns true
              if a valid js identifier"
  [name] (or (REGEX.id.test name) (REGEX.id2.test name)))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn jsid "Escape to
           compliant js identifier"
  [input]
  (var pfx "" name $(input))
  (when (and name
             (starts? name "-"))
    (=> pfx "-" name (rest name)))
  (if (testid? name)
    (reduce
      (fn [acc x]
        (=> acc
            (acc.replace (1st x) (2nd x)))
        (if (ends? acc (2nd x))
          (acc.slice 0 -1)
          acc))
      (.replace (str pfx name)
                REGEX.slash ".") REPLACERS)
    (if (= pfx "") name (str pfx name))))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- lexer "Lexical analyzer" [source fname]
  (var fform? #f esc? #f str? #f
       regex? #f comment? #f
       len (n# source)
       token "" line 1
       ch nil nx nil
       col 0 pos 0
       tline line
       tree []
       tcol col
       toke
       (fn [ln col s s?]
         (when (opt?? s? (not-empty s))
           (when (and (starts? s "&")
                      (not= s "&&")
                      (> (alen s) 1))
             (conj! tree (tnode fname ln col "&" "&"))
             (=> s (rest s)))
           (conj! tree (tnode fname ln col s s))) ""))
  (while (< pos len)
    (=> ch (ch@ source pos))
    (++ col)
    (++ pos)
    (=> nx (ch@ source pos))
    (when (= ch "\n")
      (=> col 0)
      (++ line)
      (if comment? (false! comment?)))
    (cond
      comment? nil
      esc? (do (false! esc?)
               (+= token ch))
      regex?
      (do (if (= ch "\\")
            (true! esc?))
          (+= token ch)
          (when (= ch "/")
            (false! regex?)
            (when (contains? "gimuy" nx)
              (+= token nx)
              (++ pos))
            (=> token (toke tline tcol token))))
      fform?
      (if (and (= ch "`")
               (= nx "`")
               (= (ch@ source (+1 pos)) "`"))
        (do (false! fform?)
            (+= pos 2)
            (+= token "\"")
            (=> token (toke tline tcol token true)))
        (cond (= ch "\"") (+= token "\\\"")
              (= ch "\n") (+= token "\\n")
              :else (+= token ch)))
      (and (= ch "`")
           (= nx "`")
           (= (ch@ source (+1 pos)) "`")
           (empty?  token))
      (do (=> tline line tcol col)
          (+= pos 2)
          (true! fform?)
          (+= token "\""))
      (= ch "\"")
      (if-not str?
        (do (=> tline line tcol col)
            (true! str?)
            (+= token ch))
        (do (false! str?)
            (+= token ch)
            (=> token
                (toke tline tcol token #t))))
      ;;must be after the check for string
      str?
      (do (if (= ch "\n") (=> ch "\\n"))
          (if (= ch "\\") (=> esc? #t))
          (+= token ch))
      (or (= ch "'") (= ch "`")
          (= ch "$") (= ch "@") (= ch "^"))
      (if (and (empty? token)
               (not (REGEX.wspace.test nx)))
        (do (=> tline line tcol col)
            (toke tline tcol ch))
        (+= token ch))
      (and (= ch "&")
           (= nx "&"))
      (do (if (empty? token) (=> tline line tcol col))
          (+= token (str ch nx))
          (++ pos))
      (= ch "~")
      (if (and (empty? token)
               (not (REGEX.wspace.test nx)))
        (do (=> tline line tcol col)
            (if (= nx "@")
              (do (++ pos)
                  (toke tline tcol "~@"))
              (toke tline tcol ch)))
        (+= token ch))
      (and (= ch "/")
           (empty? token))
      (do (true! regex?)
          (=> tline line tcol col)
          (+= token ch))
      (or (= ch "[")(= ch "]")
          (= ch "{")(= ch "}")
          (= ch "(")(= ch ")"))
      (do (=> token (toke tline tcol token) tline line tcol col)
          (toke tline tcol ch))
      (= ch ";")
      (=> token (toke tline tcol token) tline line tcol col comment? #t)
      (or (= ch ",")
          (REGEX.wspace.test ch))
      (->> (-> (if (= ch "\n")
                 (-1 tline) tline)
               (toke tcol token))
           (=> token))
      :else
      (do (if (empty? token)
            (=> tline line tcol col))
          (+= token ch))))
  ;;check for errors
  (var tmp {:source fname :line tline :column col})
  (if fform? (throwE tmp "unterminated free-form"))
  (if esc? (throwE tmp "incomplete escape"))
  (if str? (throwE tmp "unterminated string"))
  (if regex? (throwE tmp "unterminated regex definition"))
  tree)

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- throwE "Raise an error"
  [token & msgs]
  (var s (join "" msgs))
  (if token
    (raise! s
            "\nnear line: "
            token.line "\nin file: " token.source)
    (raise! s "\nnear EOF")))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- nextToken "Returns the next token,
                 updates the token index"
  [tokens]
  (var t (peekToken tokens)) (++ tokens.pos) t)

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- peekToken "Returns the next token,
                 without moving the token index"
  [tokens] (nth tokens tokens.pos))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- prevToken "Returns the previous token"
  [tokens] (nth tokens (-1 tokens.pos)))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- copyTokenData "Attach source level information
                     to the node"
  [token node]
  (if (or (object? node)(array? node))
    (=>> node
         :source token.source
         :line token.line
         :column token.column)) node)

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- readAtom "Process an atom"
  [tokens]
  (var ret nil tn ""
       token (nextToken tokens))
  (if token
    (=> tn token.name))
  (cond
    (empty? tn)
    (undef! ret)
    (REGEX.float.test tn)
    (=> ret (float tn))
    (or (REGEX.hex.test tn)
        (REGEX.int.test tn))
    (=> ret (int tn))
    (and (starts? tn "\"")
         (ends? tn "\""))
    (=> ret tn)
    (starts? tn ":")
    (=> ret (keyword tn))
    (starts? tn "%")
    (=> ret (lambda-arg tn))
    (or (= "nil" tn)
        (= "null" tn))
    (=> ret nil)
    (or (= "#t" tn)
        (= "true" tn))
    (=> ret true)
    (or (= "#f" tn)
        (= "false" tn))
    (=> ret false)
    :else (=> ret (symbol tn)))
  (copyTokenData token ret))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- readBlock "Process a LISP form"
  [tokens head tail]
  (var ast [] ok? #t
       start nil
       token (nextToken tokens))
  (var~ ret cur tn)
  (if token (=> tn token.name))
  (if (not= tn head)
    (throwE token "expected '" head "'"))
  (=> start token
      cur (peekToken tokens))
  (while ok?
    (when (or (nichts? cur)
              (= tail cur.name))
      (if cur
        (copyTokenData token ast)
        (throwE start "expected '" tail "', got EOF"))
      (false! ok?))
    (when ok?
      (addAst ast (read* tokens))
      (=> cur (peekToken tokens))))
  (nextToken tokens)
  ast)

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- readList "Process an expression"
  [cur tokens] (readBlock tokens "(" ")"))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- readVector "Process a Vector"
  [cur tokens]
  (into! :vector (readBlock tokens "[" "]")))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- readMap "Process a Hashmap"
  [cur tokens]
  (into! :map (readBlock tokens "{" "}")))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- skipParse "Advance the token index,
                  then continue to parse"
  [tokens func]
  (copyTokenData (nextToken tokens) (func tokens)))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- read* "Inner parser routine"
  [tokens]
  (var tmp nil token (peekToken tokens))
  (if (nichts? token)
    undefined
    (case token.name
      "'" (skipParse
            tokens
            #([(symbol "quote") (read* tokens)]))
      "`" (skipParse
            tokens
            #([(symbol "quasiquote") (read* tokens)]))
      "~" (skipParse
            tokens
            #([(symbol "unquote") (read* tokens)]))
      "~@" (skipParse
             tokens
             #([(symbol "splice-unquote") (read* tokens)]))
      "^" (skipParse
            tokens
            (fn []
              (=> tmp (read* tokens))
              [(symbol "with-meta") (read* tokens) tmp]))
      "@" (skipParse
            tokens
            #([(symbol "deref") (read* tokens)]))
      "$" (skipParse
            tokens
            #(do-with [y (read* tokens)]
               (var x (symbol "str"))
               (if (> (alen y) 1)
                 (=> y [x y])
                 (y.unshift x))))
      "#" (skipParse
            tokens
            #([(symbol "lambda") (read* tokens)]))
      ")" (throwE token "unexpected ')'")
      "(" (readList token tokens)
      "]" (throwE token "unexpected ']'")
      "[" (readVector token tokens)
      "}" (throwE token "unexpected '}'")
      "{" (readMap token tokens)
      (";" ",") (do->undef (nextToken tokens))
      ;else
      (readAtom tokens))))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn- addAst
  "" [ast f] (if-not (undef? f) (conj! ast f)) ast)

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn parse "Main parser routine"
  [source & [fname]]
  (var tokens (lexer source
                     (opt?? fname "*adhoc*"))
       f nil ast [] tlen (n# tokens))
  (=> tokens.pos 0)
  (if false
    (each #(println "token=" (.-name %)) tokens))
  (while (< tokens.pos tlen)
    (addAst ast (read* tokens))) ast)

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(defn dumpTree "Debug and dump the AST"
  [tree]
  (each #(println (prn %)) tree))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;EOF

